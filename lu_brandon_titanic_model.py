# -*- coding: utf-8 -*-
"""Lu_Brandon_Titanic_Model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hyCL0MihPNNylUYkztQ3-1BCCBOF6QDW

# Import libraries
"""

# Brandon Lu
# train_test_split is used to easily split the dataset into training and testing
from sklearn.model_selection import train_test_split
# tensorflow is used to grab a library ML model
import tensorflow as tf
# pandas is used for data manipulation
import pandas as pd

"""
# Pre-process data

---
We will only keep columns relevant to the label of surviving  
So: PassengerId, Name, Ticket, Embarked, and Cabin shouldn't matter since they shouldn't have any relevance to survival rate
- Pclass could determine where the passenger was located/how good of condition the passenger is in due to economic situations
- Sex could be a factor as males and females have different biologies
- Age could matter, as people of different ages tend to trend towards certain physical conditions
- SibSp and Parch could determine if the survivor tries to survive on their own/escape by themselves as well as if anyone could have helped them
- Fare is similar to Pclass as it is an indicator of economic status which is an indirect indicator of condition of the person

---
- Survived should be the label column  
---
Note: I could make an argument for Embarked being relevant, but I think it is trivial  
Same with cabin, but I don't wanna deal with the processing of the data and I
also think that cabin is covered with Pclass

---"""

# reading dataset into dataframe from provided dataset link using pandas
df = pd.read_csv('https://cdn.techroulette.xyz/projects/shipwreck/data/m3_data.csv')
# dropping PassengerId, Name, Ticket, Embarked from columns (axis = 1 means columns)
df = df.drop(['PassengerId', 'Name', 'Ticket', 'Embarked', 'Cabin'], axis = 1)
# replace text fields with corresponding numbers -- this means Sex and Cabin

# Sex
# we can deal with male/female as easily as 0 and 1

# pre-process Sex column
df = df.replace({'male': 0, 'female': 1})

# drop rows which don't have an age
df.drop(df[pd.isna(df['Age'])].index, inplace = True)

"""# Create training data set and testing data set"""

# save and remove the labels
  labels = df.pop('Survived')
  # remaining params
  x = df
  # split into training and testing
  x_train, x_test, labels_train, labels_test = train_test_split(x, labels, test_size = 0.3)

"""# Set up the model"""

# from my understanding, Sequential models are used for singular input singluar 
# output problems at every layer
model = tf.keras.models.Sequential()
model.add(tf.keras.layers.Dense(6, input_shape=(6,), activation="relu"))
model.add(tf.keras.layers.Dense(6, activation = "sigmoid"))
model.add(tf.keras.layers.Dense(1, activation = "sigmoid"))

"""# Train the model"""

# compile the model with adam optimizer, binary cross entropy loss function
# output accuracy metrics
model.compile(
    optimizer="adam",
    loss="binary_crossentropy",
    metrics=["accuracy"]
)
# train the data
model.fit(x_train, labels_train, epochs = 500)



"""# Test the model"""

# test the model on testing data
model.evaluate(x_test, labels_test, verbose = 2)